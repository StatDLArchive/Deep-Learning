

# ğŸ§  Deep Learning & PyTorch Study

<p align="center">
  <img src="https://img.shields.io/badge/Study-Deep%20Learning-blue?style=for-the-badge&logo=pytorch">
  <img src="https://img.shields.io/badge/Python-3.8%2B-3776AB?style=for-the-badge&logo=python&logoColor=white">
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white">
  <img src="https://img.shields.io/badge/Seminar-Weekly-2EA44F?style=for-the-badge&logo=googlemeet&logoColor=white">
</p>

> ğŸ“Œ Ian Goodfellowì˜ **Deep Learning** êµì¬ ê¸°ë°˜ + ê°ìê°€ ì•Œì•„ì„œ ì°¸ê³ ë¬¸í—Œë“¤ ì¶”ê°€  
> ì´ë¡  í•™ìŠµ + ë°œí‘œ(ìŠ¬ë¼ì´ë“œ) + ë°‘ë°”ë‹¥ êµ¬í˜„(Python/PyTorch) 

---

## ğŸ“š Main Textbook

| Cover | Title | Authors | Link |
| :---: | :--- | :--- | :---: |
| <img src="https://m.media-amazon.com/images/I/61qBJmjJcCL._SL1360_.jpg" width="120"> | **Deep Learning** | Ian Goodfellow, Yoshua Bengio, Aaron Courville | [ğŸ“– Website](https://www.deeplearningbook.org/) |

---

## ğŸ¯ Study Philosophy

ìš°ë¦¬ëŠ” Inputê³¼ Outputì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ê¹Šì´ ìˆëŠ” í•™ìŠµì„ ì§€í–¥.
í• ë•Œ ì œëŒ€ë¡œ í•˜ê¸°.

- **Input**: ê°•ì˜/êµì¬ë¡œ ê°œë…ê³¼ ìˆ˜ì‹ ì´í•´  
- **Output**: ìŠ¬ë¼ì´ë“œ ë°œí‘œ + ì½”ë“œ êµ¬í˜„ + ê¸°ë¡(ì˜ìƒ/ë…¸íŠ¸)

---

## ğŸ”„ Study Workflow

```text
Lecture / Reading
        â†“
Slide Preparation
        â†“
Seminar Presentation
        â†“
Discussion & Feedback
        â†“
Code from Scratch
        â†“
GitHub Archive (+ optional YouTube)
```

---

## ğŸ“… Weekly Routine

| ìš”ì¼ | í™œë™ ë‚´ìš© | ë¹„ê³  |
| :---: | :--- | :--- |
| **ì›” ~ ìˆ˜** | **Individual Study**<br>- ê°•ì˜ ìˆ˜ê°• ë° êµì¬ ì½ê¸°<br>- ê°œë… ì •ë¦¬ ì´ˆì•ˆ(Draft) ì‘ì„± | ê°œë³„ í•™ìŠµ |
| **ëª© ~ ê¸ˆ** | **Group Study**<br>- ì‹¬í™” ì¡°ì‚¬ ë° ìë£Œ ì •ë¦¬<br>- ìŠ¬ë¼ì´ë“œ & ì½”ë“œ ì™„ì„± | íŒ€ í•™ìŠµ |
| **í† ** | **Main Seminar**<br>- ë°œí‘œ + Q&A + í”¼ë“œë°± | ë©”ì¸ ì„¸ë¯¸ë‚˜ |

---

## ğŸ—“ Curriculum

> **ê¸°ê°„**: 2026ë…„ 1ì›” 12ì¼ ~ 4ì›” 19ì¼ (ì˜ˆì •)

| Week | Date | Topic | Chapter |
| :---: | :--- | :--- | :---: |
| **1** | 01.12 ~ 01.18 | Foundations of Deep Learning | 1 |
| **2** | 01.19 ~ 01.25 | Neuron Modeling Deep & Feedforward Networks | 2, 3 |
| **3** | 01.26 ~ 02.01 | Optimization | 4 |
| **4** | 02.02 ~ 02.08 | Regularization | 5 |
| **5** | 02.09 ~ 02.15 | Convolutional Neural Nets (Part 1) | 6 |
| **6** | 02.16 ~ 02.22 | Convolutional Neural Nets (Part 2) | 7 |
| **7** | 02.23 ~ 03.01 | The Art of Neural Net Training | 8 |
| **8** | 03.02 ~ 03.08 | CNN Architectures | 9 |
| **9** | 03.09 ~ 03.15 | Recurrent Neural Nets (RNN) | 10 |
| **10** | 03.16 ~ 03.22 | Gated Recurrent Neural Nets (LSTM/GRU) | 11 |
| **11** | 03.23 ~ 03.29 | Attention and Transformer | 12 |
| **12** | 03.30 ~ 04.05 | Introduction to Generative Models | 13 |
| **13** | 04.06 ~ 04.12 | Variational Autoencoder (VAE) | 14 |
| **14** | 04.13 ~ 04.19 | Generative Adversarial Network (GAN) | 15 |

---

## ğŸ‘¥ Team

| Name | Role | GitHub |
| :--- | :--- | :--- |
| **Member1** | Presenter | [@ê¹€ìƒí˜„](https://github.com/ddanghyni) |
| **Member2** | Presenter | [@ì •ë¯¼êµ](https://github.com/DEVJmK) |

---

## ğŸ“‚ Repository Structure (ì˜ˆì‹œ)

```bash
â”œâ”€â”€ 01_Foundations/               # ì£¼ì°¨ë³„ í´ë”
â”‚   â”œâ”€â”€ Kim/                      # ë©¤ë²„ë³„ í´ë”
â”‚   â”‚   â”œâ”€â”€ slides.pdf            # ë°œí‘œ ìë£Œ
â”‚   â”‚   â”œâ”€â”€ code.ipynb            # êµ¬í˜„ ì½”ë“œ
â”‚   â”‚   â””â”€â”€ notes.md              # (ì„ íƒ) ì •ë¦¬ ë…¸íŠ¸
â”‚   â””â”€â”€ Park/
â”œâ”€â”€ 02_Feedforward/
â”œâ”€â”€ 03_Optimization/
â”œâ”€â”€ 04_Regularization/
â”œâ”€â”€ 05_CNN_1/
â”œâ”€â”€ 06_CNN_2/
â”œâ”€â”€ 07_Training_Techniques/
â”œâ”€â”€ 08_CNN_Architectures/
â”œâ”€â”€ 09_RNN/
â”œâ”€â”€ 10_LSTM_GRU/
â”œâ”€â”€ 11_Transformer/
â”œâ”€â”€ 12_Generative_Models/
â”œâ”€â”€ 13_VAE/
â”œâ”€â”€ 14_GAN/
â”œâ”€â”€ resources/                    # (ì„ íƒ) ì°¸ê³ ìë£Œ/ë§í¬/ë…¼ë¬¸
â””â”€â”€ README.md
```

---

## ğŸ§ª Implementations (from scratch)
> ê°ì êµ¬í˜„í•œ ë¶€ë¶„ë“¤ ì •ë¦¬ 

- Linear / Logistic Regression (example)


---

## ğŸ“„ Paper Reading Log
> ì½ì€ ë…¼ë¬¸ ì •ë¦¬

| Date | Paper | Topic | Presenter | Notes |
| :--- | :--- | :--- | :--- | :--- |
| 2026-02-01 | Attention Is All You Need | Transformer | Member1 | link |
| 2026-03-10 | GAN | Generative Models | Member2 | link |

---

## âœ… Rules

- **ìŠ¬ë¼ì´ë“œ/ì½”ë“œ/ë…¸íŠ¸ëŠ” ìµœì†Œ ì„¸ë¯¸ë‚˜ ì „ë‚ ê¹Œì§€ ì—…ë¡œë“œ**
- PR ë˜ëŠ” ì»¤ë°‹ ë©”ì‹œì§€ì— `week-xx` íƒœê·¸ ê¶Œì¥  
  - ì˜ˆ: `week-03: add optimization notes`
- **ì½”ë“œëŠ” ì¬í˜„ ê°€ëŠ¥**í•˜ê²Œ (seed / requirements / data note)
- ë§¤ì£¼ ë°œí‘œë¥¼ ì§„í–‰í• ë•Œ ê·¸ ì£¼ì°¨ì— í•´ë‹¹í•˜ëŠ” ì£¼ì œê°€ ì•„ë‹Œ ê°ìê°€ ì¶”ê°€ë¡œ ê³µë¶€í•œ ë¶€ë¶„ë„ ê³µìœ 

---


